
<!doctype html>
<html lang="en">
<head>
  <title>Mohsen Ghafoorian</title>
  <meta name="description" content="Mohsen Ghafoorian, Homepage" />
  <meta name="keywords" content="mohsen ghafoorian, radboud, deep learning, machine learning ,reinforcement learning" />
  <meta http-equiv="content-type" content="text/html; charset=UTF-8" />
  <link rel="stylesheet" type="text/css" href="http://fonts.googleapis.com/css?family=Tangerine&amp;v1" />
  <link rel="stylesheet" type="text/css" href="http://fonts.googleapis.com/css?family=Yanone+Kaffeesatz" />
  <link rel="stylesheet" type="text/css" href="style/style.css" />
  <script type="text/javascript">
  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-7159236-4']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();
  </script>
  <style>
    /* ====== Base (match your site's vibe + stripes) ====== */
    :root{
      --bg-1:#fafbff;
      --bg-2:#f1f4ff;
      --text:#121212;
      --muted:#616161;
      --card:#ffffffee;
      --border:#e6e6eb;
      --accent:#0d6efd;
      --accent-2:#14b8a6;
      --award:#d97706;
      --shadow:0 1px 2px rgba(0,0,0,.06), 0 8px 20px rgba(0,0,0,.07);
      --radius:14px;
      --maxw:1100px;
    }
    @media (prefers-color-scheme: dark){
      :root{
        --bg-1:#0b0b0d;
        --bg-2:#0f1013;
        --text:#f2f3f5;
        --muted:#c9c9ce;
        --card:#15161aee;
        --border:#22252a;
        --shadow:none;
      }
    }

    /* ====== Header (Home / Publications / CV / Contact) ====== */
    .nav-wrap{
      backdrop-filter:saturate(160%) blur(6px);
      position:sticky; top:0; z-index:20;
      border-bottom:1px solid var(--border);
      background:linear-gradient(to bottom, #fff8, #fff4);
    }
    @media (prefers-color-scheme: dark){
      .nav-wrap{ background:linear-gradient(to bottom, #0006, #0003); }
    }
    .nav{
      max-width:var(--maxw);
      margin:0 auto; padding:14px 20px;
      display:flex; align-items:center; justify-content:space-between;
    }
    .brand{
      display:flex; align-items:center; gap:10px;
      font-weight:700; letter-spacing:.2px; font-size:18px;
    }
    .brand img{height:22px; width:auto; border-radius:4px}
    .nav ul{list-style:none; margin:0; padding:0; display:flex; gap:18px}
    .nav a{
      color:var(--muted); text-decoration:none; padding:6px 10px; border-radius:8px;
    }
    .nav a:hover{color:var(--text); background:#00000009}
    .nav a.active{
      color:#0a3a90; background:#eaf2ff; border:1px solid #cfe0ff;
    }

    /* ====== Page ====== */
    .page{max-width:var(--maxw); margin:0 auto; padding:24px 20px;}
    .page h1{margin:12px 0 6px; font-size:28px; letter-spacing:.1px;}
    .page .subtitle{color:var(--muted); margin:0 0 24px; font-size:15px;}

    /* ====== Grid ====== */
    .grid{display:grid; grid-template-columns:repeat(1,minmax(0,1fr)); gap:22px;}
    @media(min-width:720px){ .grid{grid-template-columns:repeat(2,minmax(0,1fr))} }
    @media(min-width:1060px){ .grid{grid-template-columns:repeat(3,minmax(0,1fr))} }

    /* ====== Card ====== */
    .card{
      background:var(--card); border:1px solid var(--border);
      border-radius:var(--radius); box-shadow:var(--shadow);
      overflow:hidden; display:flex; flex-direction:column;
    }
    .content{padding:14px 14px 16px; display:flex; flex-direction:column; gap:10px}
	
	.card {
	  transition: transform 0.15s ease, box-shadow 0.15s ease;
	}

	.card:hover {
	  transform: translateY(-4px); /* Moves up by 4px */
	  box-shadow: 0 4px 12px rgba(0, 0, 0, 0.12); /* Optional: stronger shadow */
	}

    /* ====== Teaser figure (inline SVG or img) ====== */
    .teaser{
      aspect-ratio:16/9; background:#eef3ff; border-bottom:1px solid var(--border);
      display:block;
    }
    .teaser svg, .teaser img{width:100%; height:100%; display:block}
    .teaser figcaption{
      display:none; /* caption available if needed */
      padding:8px 12px; font-size:12px; color:var(--muted);
    }

    /* ====== Title & meta ====== */
    .title{font-weight:600; font-size:16.5px; line-height:1.45; margin:0;}
    .title a{color:inherit; text-decoration:none; border-bottom:2px solid transparent;}
    .title a:hover{color:var(--accent); border-color:var(--accent);}
    .authors{color:var(--muted); font-size:14px; margin-top:-6px;}

    /* ====== Pills ====== */
    .pills{display:flex; flex-wrap:wrap; gap:8px; margin-top:2px;}
    
	.pill {
	  display: inline-flex;
	  align-items: center;
	  gap: 6px;
	  padding: 6px 10px;
	  border-radius: 4px;       /* Change from 999px to something small */
	  font-size: 12.5px;
	  font-weight: 600;
	  background: #eaf2ff;
	  color: #0a3a90;
	  border: 1px solid #cfe0ff;
	}

    .pill.secondary{ background:#eafffb; color:#0a6d64; border:1px solid #c9f2ec; }
    .pill.award{ background:#fff3e6; color:#7a4b00; border:1px solid #ffe0bd; }

    /* ====== Badges ====== */
    .links{margin-top:4px; display:flex; flex-wrap:wrap; gap:8px}
    .badge{
      display:inline-flex; align-items:center; gap:8px; padding:6px 10px;
      border-radius:10px; font-size:12.5px; font-weight:600;
      color:#0e2a4c; background:#eef3ff; border:1px solid #dbe6ff; text-decoration:none;
    }
    .badge:hover{background:#e3ecff}
    .badge.code{ color:#0b3b36; background:#e9fbf7; border-color:#c9efe6; }
    .badge.video{ color:#36120b; background:#fff0ea; border-color:#ffd9ce; }
    .badge.poster{ color:#3d2a0e; background:#fff8e8; border-color:#ffe9bb; }

    /* ====== Copy BibTeX ====== */
    .copybtn{
      cursor:pointer; user-select:none; display:inline-flex; align-items:center; gap:8px;
      padding:6px 10px; border-radius:10px; font-size:12.5px; font-weight:600;
      color:#102a1a; background:#eaffe8; border:1px solid #c9f2c6;
    }
    .copybtn:hover{ background:#dcffd5 }
    .bibtex{ display:none; white-space:pre-wrap; font-size:12px; }

    /* ====== Footer (social links from your homepage) ====== */
    footer{
      border-top:1px solid var(--border);
      background:linear-gradient(to top, #fff8, #fff4);
      margin-top:24px;
    }
    @media (prefers-color-scheme: dark){
      footer{ background:linear-gradient(to top, #0006, #0003); }
    }
    .footer{
      max-width:var(--maxw); margin:0 auto; padding:16px 20px;
      display:flex; flex-wrap:wrap; align-items:center; justify-content:space-between; gap:10px;
      color:var(--muted); font-size:13px;
    }
    .social{display:flex; flex-wrap:wrap; gap:12px}
    .social a{
      color:var(--muted); text-decoration:none; padding:4px 8px; border-radius:8px;
      border:1px solid transparent;
    }
    .social a:hover{ color:var(--text); border-color:var(--border); background:#00000009 }
	

	.teaser {
	  display: flex;
	  align-items: center;
	  justify-content: center;
	  background-color: #fff;
	  height: 180px;           /* or use aspect-ratio: 16/9 */
	  overflow: hidden;
	}
	.teaser img {
	  max-width: 100%;
	  max-height: 100%;
	  object-fit: contain;
	}

  </style>
</head>
<body>
	<div id="main">
  <!-- ====== Header ====== -->
      <div id="header">
      <div id="logo">
      </div>
      <div id="menubar">

        <ul id="menu">
          <!-- put class="current" in the li tag for the selected page - to highlight which page you're on -->
          <li ><a href="index.html">Home</a></li>
          <!--<li ><a href="research.html">Research</a></li>-->
          <li  class="current"><a href="publications.html">Publications</a></li>
          <li ><a href="cv.html">CV</a></li>
          <!--<li ><a href="presentations.html">Talks</a></li>-->
          <li ><a href="contact.html">Contact</a></li>
        </ul>
      </div>
    </div>

<div id="site_content">
<div id="content">
  <main class="page">
    <h1>Recent Publications</h1>
	<p></p>

    <!-- ====== Grid ====== -->
    <section class="grid" aria-label="Publications">
      
  
	  <!-- 1. CVPR 2025 — Attn surgery -->
		<article class="card" id="pub-attention-surgery">
		    <figure class="teaser">
			<img src="images/teasers/surgery.png" alt="Attention Surgery teaser"h2 class="title">
			</figure>
			<div class="content">
			<h2 class="title">
		
			  <a href="https://arxiv.org/abs/2509.24899" target="_blank" rel="noopener">
				Attention Surgery: An Efficient Recipe to Linearize Your Video Diffusion Transformer
			  </a>
			</h2>
			<div class="authors"><strong> M. Ghafoorian</strong>, D. Korzhenkov, A. Habibian</div>
			<div class="pills"><span class="pill">arXiv 2025</span></div>
			<div class="links">
			  <a class="badge" href="https://arxiv.org/abs/2509.24899" target="_blank">Paper</a>
			  <a class="badge" href="https://qualcomm-ai-research.github.io/attention-surgery/" target="_blank">Project Page</a>
			  <button class="copybtn" onclick="copyBib('bib-attention-surgery')">Copy BibTeX</button>
			</div>
			<pre class="bibtex" id="bib-attention-surgery">@article{Ghafoorian2025AttentionSurgery,
		  title={Attention Surgery: An Efficient Recipe to Linearize Your Video Diffusion Transformer},
		  author={Mohsen Ghafoorian and Denis Korzhenkov and Amirhossein Habibian},
		  journal={arXiv preprint arXiv:2509.24899},
		  year={2025},
		  url={https://arxiv.org/abs/2509.24899}
		}</pre>
		  </div>
		</article>


		<article class="card" id="pub-moalign">
		  <figure class="teaser">
			<img src="images/teasers/moalign.png" alt="moalign teaser"h2 class="title">
		  </figure>
		  <div class="content">
			<h2 class="title">
			  <a href="https://arxiv.org/abs/2510.19022" target="_blank" rel="noopener">
				MoAlign: Motion-Centric Representation Alignment for Video Diffusion Models
			  </a>
			</h2>
			<div class="authors">A. Bhowmik, D. Korzhenkov, C. Snoek, A. Habibian, <strong>M. Ghafoorian</strong></div>
			<div class="pills"><span class="pill">arXiv 2025</span></div>
			<div class="links">
			  <a class="badge" href="https://arxiv.org/abs/2510.19022" target="_blank">Paper</a>
			  <button class="copybtn" onclick="copyBib('bib-moalign')">Copy BibTeX</button>
			</div>
			<pre class="bibtex" id="bib-moalign">@article{Bhowmik2025MoAlign,
		  title={MoAlign: Motion-Centric Representation Alignment for Video Diffusion Models},
		  author={Aritra Bhowmik and Denis Korzhenkov and Cees G. M. Snoek and Amirhossein Habibian and Mohsen Ghafoorian},
		  journal={arXiv preprint arXiv:2510.19022},
		  year={2025},
		  url={https://arxiv.org/abs/2510.19022}
		}</pre>
		  </div>
		</article>
		
		
		<article class="card" id="pub-neodragon">
		  <figure class="teaser">
			<img src="images/teasers/neodragon.png" alt="neodragon teaser"h2 class="title">
		  </figure>
		  <div class="content">
			<h2 class="title">
			  <a href="https://arxiv.org/abs/2511.06055" target="_blank" rel="noopener">
				NeoDragon: Mobile Video Generation using Diffusion Transformer
			  </a>
			</h2>
			<div class="authors">A. Karnewar, D. Korzhenkov, I. Lelekas, A. Karjauv, N. Fathima, H. Xiong, V. Vaidyanathan, W. Zeng, R. Esteves, T. Singhal, F. Porikli, <strong>M. Ghafoorian</strong>, A. Habibian</div>
			<div class="pills"><span class="pill">arXiv 2025</span></div>
			<div class="links">
			  <a class="badge" href="https://arxiv.org/abs/2511.06055" target="_blank">Paper</a>
			  <a class="badge" href="https://qualcomm-ai-research.github.io/neodragon/" target="_blank">Project Page</a>
			  <button class="copybtn" onclick="copyBib('bib-neodragon')">Copy BibTeX</button>
			</div>
			<pre class="bibtex" id="bib-neodragon">@article{Karnewar2025NeoDragon,
		  title={NeoDragon: Mobile Video Generation using Diffusion Transformer},
		  author={Animesh Karnewar and Denis Korzhenkov and Ioannis Lelekas and Adil Karjauv and Noor Fathima and Hanwen Xiong and Vancheeswaran Vaidyanathan and Will Zeng and Rafael Esteves and Tushar Singhal and Fatih Porikli and Mohsen Ghafoorian and Amirhossein Habibian},
		  journal={arXiv preprint arXiv:2511.06055},
		  year={2025},
		  url={https://arxiv.org/abs/2511.06055}
		}</pre>
		  </div>
		</article>
	  
	  <!-- 1. CVPR 2025 — AnyMap -->
      <article class="card" id="pub-anymap">
        <figure class="teaser" aria-label="AnyMap schematic">
          <img src="images/teasers/anymap.png" alt="anymap teaser"h2 class="title">
        </figure>
        <div class="content">
          <h2 class="title">
            <a href="https://openaccess.thecvf.com/content/CVPR2025/papers/Dal_Cin_AnyMap_Learning_a_General_Camera_Model_for_Structure-from-Motion_with_Unknown_CVPR_2025_paper.pdf" target="_blank" rel="noopener">
              AnyMap: Learning a General Camera Model for Structure‑from‑Motion with Unknown Distortion in Dynamic Scenes
            </a>
          </h2>
          <div class="authors">A. Porfiri Dal Cin, G. Dikov, J. Ju, <strong>M. Ghafoorian</strong></div>
          <div class="pills"><span class="pill">CVPR 2025</span></div>
          <div class="links">
            <a class="badge" href="https://openaccess.thecvf.com/content/CVPR2025/papers/Dal_Cin_AnyMap_Learning_a_General_Camera_Model_for_Structure-from-Motion_with_Unknown_CVPR_2025_paper.pdf" target="_blank" rel="noopener">Paper (CVF)</a>
           <button class="copybtn" onclick="copyBib('bib-anymap')">Copy BibTeX</button>
          </div>
          <pre class="bibtex" id="bib-anymap">@inproceedings{DalCin2025AnyMap,
  author    = {Andrea Porfiri Dal Cin and Georgi Dikov and Jihong Ju and Mohsen Ghafoorian},
  title     = {AnyMap: Learning a General Camera Model for Structure-from-Motion with Unknown Distortion in Dynamic Scenes},
  booktitle = {IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year      = {2025},
  doi       = {10.1109/CVPR52734.2025.01554},
  url       = {https://openaccess.thecvf.com/content/CVPR2025/papers/Dal_Cin_AnyMap_Learning_a_General_Camera_Model_for_Structure-from-Motion_with_Unknown_CVPR_2025_paper.pdf}
}</pre>
        </div>
      </article>

      <!-- 2. ECCV 2024 — FastCAD -->
      <article class="card" id="pub-fastcad">
        <figure class="teaser" aria-label="FastCAD schematic">
          <img src="images/teasers/fastcad.png" alt="fastcad teaser"h2 class="title">
        </figure>
        <div class="content">
          <h2 class="title">
            <a href="https://arxiv.org/abs/2403.15161" target="_blank" rel="noopener">
              FastCAD: Real‑Time CAD Retrieval and Alignment from Scans and Videos
            </a>
          </h2>
          <div class="authors">F. Langer, J. Ju, G. Dikov, G. Reitmayr, <strong>M. Ghafoorian</strong></div>
          <div class="pills"><span class="pill">ECCV 2024</span></div>
          <div class="links">
            <a class="badge" href="https://arxiv.org/abs/2403.15161" target="_blank" rel="noopener">Paper (arXiv)</a>
            <a class="badge" href="https://florianlanger.github.io/FastCAD/" target="_blank" rel="noopener">Project Page</a>
            <button class="copybtn" onclick="copyBib('bib-fastcad')">Copy BibTeX</button>
          </div>
          <pre class="bibtex" id="bib-fastcad">@inproceedings{Langer2024FastCAD,
  author    = {Florian Langer and Jihong Ju and Georgi Dikov and Gerhard Reitmayr and Mohsen Ghafoorian},
  title     = {FastCAD: Real-Time CAD Retrieval and Alignment from Scans and Videos},
  booktitle = {European Conference on Computer Vision (ECCV)},
  series    = {Lecture Notes in Computer Science},
  volume    = {15073},
  pages     = {60--77},
  year      = {2024},
  publisher = {Springer},
  doi       = {10.1007/978-3-031-72633-0_4},
  url       = {https://arxiv.org/abs/2403.15161}
}</pre>
        </div>
      </article>

      <!-- 3. BMVC 2024 — InterroGate -->
      <article class="card" id="pub-interrogate">
        <figure class="teaser" aria-label="InterroGate schematic">
          <img src="images/teasers/interrogate.png" alt="interrogate teaser"h2 class="title">
        </figure>
        <div class="content">
          <h2 class="title">
            <a href="https://bmvc2024.org/proceedings/54/" target="_blank" rel="noopener">
              InterroGate: Learning to Share, Specialize, and Prune Representations for Multi‑Task Learning
            </a>
          </h2>
          <div class="authors">B. Ehteshami, G. Kumar, A. Royer, C. Louizos, T. Blankevoort, <strong>M. Ghafoorian</strong></div>
          <div class="pills"><span class="pill">BMVC 2024</span></div>
          <div class="links">
            <a class="badge poster" href="https://bmva-archive.org.uk/bmvc/2024/papers/Paper_54/supplementary54.pdf" target="_blank" rel="noopener">Supplementary</a>
            <a class="badge video" href="https://bmvc2024.org/proceedings/54/" target="_blank" rel="noopener">Video</a>
            <a class="badge" href="https://arxiv.org/abs/2402.16848" target="_blank" rel="noopener">arXiv</a>
            <button class="copybtn" onclick="copyBib('bib-interrogate')">Copy BibTeX</button>
          </div>
          <pre class="bibtex" id="bib-interrogate">@inproceedings{Bejnordi2024InterroGate,
  author    = {Babak Ehteshami Bejnordi and Gaurav Kumar and Amelie Royer and Christos Louizos and Tijmen Blankevoort and Mohsen Ghafoorian},
  title     = {InterroGate: Learning to Share, Specialize, and Prune Representations for Multi-task Learning},
  booktitle = {British Machine Vision Conference (BMVC)},
  address   = {Glasgow, UK},
  year      = {2024},
  publisher = {BMVA},
  url       = {https://papers.bmvc2024.org/0054.pdf}
}</pre>
        </div>
      </article>

      <!-- 4. ICCV 2023 — 3D Distillation -->
      <article class="card" id="pub-3ddistillation">
        <figure class="teaser" aria-label="3D Distillation schematic">
          <img src="images/teasers/3dd.png" alt="3ddistillation teaser"h2 class="title">
        </figure>
        <div class="content">
          <h2 class="title">
            <a href="https://openaccess.thecvf.com/content/ICCV2023/papers/Shi_3D_Distillation_Improving_Self-Supervised_Monocular_Depth_Estimation_on_Reflective_Surfaces_ICCV_2023_paper.pdf" target="_blank" rel="noopener">
              3D Distillation: Improving Self‑Supervised Monocular Depth Estimation on Reflective Surfaces
            </a>
          </h2>
          <div class="authors">X. Shi, G. Dikov, G. Reitmayr, T.‑K. Kim, <strong>M. Ghafoorian</strong></div>
          <div class="pills"><span class="pill">ICCV 2023</span></div>
          <div class="links">
            <a class="badge" href="https://openaccess.thecvf.com/content/ICCV2023/papers/Shi_3D_Distillation_Improving_Self-Supervised_Monocular_Depth_Estimation_on_Reflective_Surfaces_ICCV_2023_paper.pdf" target="_blank" rel="noopener">Paper (CVF)</a>
            <button class="copybtn" onclick="copyBib('bib-3ddistillation')">Copy BibTeX</button>
          </div>
          <pre class="bibtex" id="bib-3ddistillation">@inproceedings{Shi2023Distillation,
  author    = {Xuepeng Shi and Georgi Dikov and Gerhard Reitmayr and Tae-Kyun Kim and Mohsen Ghafoorian},
  title     = {3D Distillation: Improving Self-Supervised Monocular Depth Estimation on Reflective Surfaces},
  booktitle = {IEEE/CVF International Conference on Computer Vision (ICCV)},
  pages     = {9099--9109},
  year      = {2023},
  doi       = {10.1109/ICCV51070.2023.00838},
  url       = {https://openaccess.thecvf.com/content/ICCV2023/papers/Shi_3D_Distillation_Improving_Self-Supervised_Monocular_Depth_Estimation_on_Reflective_Surfaces_ICCV_2023_paper.pdf}
}</pre>
        </div>
      </article>

      <!-- 5. ICCV 2023 — DG-Recon -->
      <article class="card" id="pub-dgrecon">
        <figure class="teaser" aria-label="DG-Recon schematic">
          <img src="images/teasers/dgrecon.png" alt="DGRecon teaser"h2 class="title">
        </figure>
        <div class="content">
          <h2 class="title">
            <a href="https://www.computer.org/csdl/proceedings-article/iccv/2023/071800s8138/1TJfP1P6grm" target="_blank" rel="noopener">
              DG‑Recon: Depth‑Guided Neural 3D Scene Reconstruction
            </a>
          </h2>
          <div class="authors">J. Ju, C.‑W. Tseng, O. Bailo, G. Dikov, <strong>M. Ghafoorian</strong></div>
          <div class="pills"><span class="pill">ICCV 2023</span></div>
          <div class="links">
            <a class="badge" href="https://openaccess.thecvf.com/content/ICCV2023/papers/Ju_DG-Recon_Depth-Guided_Neural_3D_Scene_Reconstruction_ICCV_2023_paper.pdf" target="_blank" rel="noopener">Paper (CVF)</a>
			<a class="badge video" href="https://www.youtube.com/watch?v=I8B31pOrxMs" target="_blank" rel="noopener">Video (YouTube)</a>
            <a class="badge poster" href="https://openaccess.thecvf.com/content/ICCV2023/supplemental/Ju_DG-Recon_Depth-Guided_Neural_ICCV_2023_supplemental.pdf" target="_blank" rel="noopener">Supplementary (CVF)</a>
            <button class="copybtn" onclick="copyBib('bib-dgrecon')">Copy BibTeX</button>
          </div>
          <pre class="bibtex" id="bib-dgrecon">@inproceedings{Ju2023DGRecon,
  author    = {Jihong Ju and Ching-Wei Tseng and Oleksandr Bailo and Georgi Dikov and Mohsen Ghafoorian},
  title     = {DG-Recon: Depth-Guided Neural 3D Scene Reconstruction},
  booktitle = {IEEE/CVF International Conference on Computer Vision (ICCV)},
  pages     = {18138--18148},
  year      = {2023},
  doi       = {10.1109/ICCV51070.2023.01667},
  url       = {https://www.computer.org/csdl/proceedings-article/iccv/2023/071800s8138/1TJfP1P6grm}
}</pre>
        </div>
      </article>

      <!-- 6. BMVC 2022 — MTD-GNN -->
      <article class="card" id="pub-mtdgnn">
        <figure class="teaser" aria-label="MTD-GNN schematic">
          <img src="images/teasers/mtd.png" alt="MTD-GNN teaser"h2 class="title">
        </figure>
        <div class="content">
          <h2 class="title">
            <a href="https://bmvc2022.mpi-inf.mpg.de/0968.pdf" target="_blank" rel="noopener">
              Multi‑Task Edge Prediction in Temporally‑Dynamic Video Graphs
            </a>
          </h2>
          <div class="authors">O. Ülger, J. Wiederer, <strong>M. Ghafoorian</strong>, V. Belagiannis, P. Mettes</div>
          <div class="pills"><span class="pill">BMVC 2022</span></div>
          <div class="links">
            <a class="badge" href="https://bmvc2022.mpi-inf.mpg.de/0968.pdf" target="_blank" rel="noopener">Paper (BMVC)</a>
			<a class="badge poster" href="https://bmvc2022.mpi-inf.mpg.de/0968_poster.pdf" target="_blank" rel="noopener">Poster</a>
     
            <button class="copybtn" onclick="copyBib('bib-mtdgnn')">Copy BibTeX</button>
          </div>
          <pre class="bibtex" id="bib-mtdgnn">@inproceedings{Ulger2022MTD-GNN,
  author    = {Osman {\\"U}lger and Julian Wiederer and Mohsen Ghafoorian and Vasileios Belagiannis and Pascal Mettes},
  title     = {Multi-Task Edge Prediction in Temporally-Dynamic Video Graphs},
  booktitle = {British Machine Vision Conference (BMVC)},
  year      = {2022},
  url       = {https://bmvc2022.mpi-inf.mpg.de/0968.pdf}
}</pre>
        </div>
      </article>

      <!-- 7. ICDIP 2021 — EADER -->
      <article class="card" id="pub-eader">
        <figure class="teaser" aria-label="EADER schematic">
          <img src="images/teasers/eader.png" alt="EADER teaser"h2 class="title">
        </figure>
        <div class="content">
          <h2 class="title">
            <a href="https://arxiv.org/abs/2011.04626" target="_blank" rel="noopener">
              Find it if You Can: End‑to‑End Adversarial Erasing for Weakly‑Supervised Semantic Segmentation
            </a>
          </h2>
          <div class="authors">E. Stammes, T. Runia, M. Hofmann, <strong>M. Ghafoorian</strong></div>
          <div class="pills">
            <span class="pill">ICDIP 2021</span>
            <span class="pill award">Best Paper Award</span>
          </div>
          <div class="links">
            <a class="badge" href="https://arxiv.org/abs/2011.04626" target="_blank" rel="noopener">Paper (arXiv)</a>
            <a class="badge" href="https://mohsenghafoorian.github.io/files/eader_presentation.pdf" target="_blank" rel="noopener">Presentation</a>
            <a class="badge code" href="https://github.com/ErikStammes/EADER" target="_blank" rel="noopener">Code</a>
            <button class="copybtn" onclick="copyBib('bib-eader')">Copy BibTeX</button>
          </div>
          <pre class="bibtex" id="bib-eader">@inproceedings{Stammes2021EADER,
  author    = {Erik Stammes and Tom F. H. Runia and Michael Hofmann and Mohsen Ghafoorian},
  title     = {Find it if You Can: End-to-End Adversarial Erasing for Weakly-Supervised Semantic Segmentation},
  booktitle = {International Conference on Digital Image Processing (ICDIP)},
  year      = {2021},
  url       = {https://arxiv.org/abs/2011.04626}
}</pre>
        </div>
      </article>

      <!-- 8. MLMI (MICCAI Workshop) 2020 — Gambling Ultrasound -->
      <article class="card" id="pub-gambling-ultrasound">
        <figure class="teaser" aria-label="Gambling Nets schematic">
          <img src="images/teasers/tus_gamb.png" alt="TUS Gamb. Adv. Nets teaser"h2 class="title">
        </figure>
        <div class="content">
          <h2 class="title">
            <a href="https://link.springer.com/chapter/10.1007/978-3-030-59861-7_52" target="_blank" rel="noopener">
              Gambling Adversarial Nets for Hard Sample Mining and Structured Prediction: Application in Ultrasound Thyroid Nodule Segmentation
            </a>
          </h2>
          <div class="authors">M. Bakhtiariziabari, <strong>M. Ghafoorian</strong></div>
          <div class="pills"><span class="pill secondary">MICCAI 2020 MLMI</span></div>
          <div class="links">
			<a class="badge" href="https://mohsenghafoorian.github.io/files/gamb_tus.pdf" target="_blank" rel="noopener">Paper</a>
            <a class="badge video" href="https://www.youtube.com/watch?v=LFsmhYGZfLI" target="_blank" rel="noopener">Video (YouTube)</a>
            <button class="copybtn" onclick="copyBib('bib-gambling-ultrasound')">Copy BibTeX</button>
          </div>
          <pre class="bibtex" id="bib-gambling-ultrasound">@inproceedings{Bakhtiariziabari2020GamblingUltrasound,
  author    = {Masoumeh Bakhtiariziabari and Mohsen Ghafoorian},
  title     = {Gambling Adversarial Nets for Hard Sample Mining and Structured Prediction: Application in Ultrasound Thyroid Nodule Segmentation},
  booktitle = {International Workshop on Machine Learning in Medical Imaging (MLMI), MICCAI},
  series    = {Lecture Notes in Computer Science},
  volume    = {12436},
  pages     = {513--522},
  year      = {2020},
  publisher = {Springer},
  doi       = {10.1007/978-3-030-59861-7_52},
  url       = {https://link.springer.com/chapter/10.1007/978-3-030-59861-7_52}
}</pre>
        </div>
      </article>

      <!-- 9. ICCV 2019 (Workshop) — Gambling Segmentation -->
      <article class="card" id="pub-gambling-seg">
        <figure class="teaser" aria-label="Gambling Adversarial segmentation schematic">
          <img src="images/teasers/gamb.png" alt="Gamb. Adv. Nets teaser"h2 class="title">
        </figure>
        <div class="content">
          <h2 class="title">
            <a href="https://openaccess.thecvf.com/content_ICCVW_2019/papers/CVRSUAD/Samson_I_Bet_You_Are_Wrong_Gambling_Adversarial_Networks_for_Structured_ICCVW_2019_paper.pdf" target="_blank" rel="noopener">
              I Bet You Are Wrong: Gambling Adversarial Networks for Structured Semantic Segmentation
            </a>
          </h2>
          <div class="authors">L. Samson, N. van Noord, O. Booij, M. Hofmann, E. Gavves, <strong>M. Ghafoorian</strong></div>
          <div class="pills">
            <span class="pill">ICCV 2019 CVRSUAD</span>
          </div>
          <div class="links">
            <a class="badge" href="https://openaccess.thecvf.com/content_ICCVW_2019/papers/CVRSUAD/Samson_I_Bet_You_Are_Wrong_Gambling_Adversarial_Networks_for_Structured_ICCVW_2019_paper.pdf" target="_blank" rel="noopener">Paper (CVF)</a>
            <a class="badge code" href="https://github.com/laurenssam/Gambling-Adversarial-Networks" target="_blank" rel="noopener">Code</a>
            <a class="badge poster" href="https://mohsenghafoorian.github.io/files/gambnets_poster.pdf" target="_blank" rel="noopener">Poster</a>
            <button class="copybtn" onclick="copyBib('bib-gambling-seg')">Copy BibTeX</button>
          </div>
          <pre class="bibtex" id="bib-gambling-seg">@inproceedings{Samson2019GamblingSeg,
  author    = {Laurens Samson and Nanne van Noord and Olaf Booij and Michael Hofmann and Efstratios Gavves and Mohsen Ghafoorian},
  title     = {I Bet You Are Wrong: Gambling Adversarial Networks for Structured Semantic Segmentation},
  booktitle = {IEEE/CVF International Conference on Computer Vision Workshops (ICCVW)},
  year      = {2019},
  url       = {https://openaccess.thecvf.com/content_ICCVW_2019/papers/CVRSUAD/Samson_I_Bet_You_Are_Wrong_Gambling_Adversarial_Networks_for_Structured_ICCVW_2019_paper.pdf}
}</pre>
        </div>
      </article>

      <!-- 10. ECCV 2018 (Workshop) — EL-GAN -->
      <article class="card" id="pub-elgan">
        <figure class="teaser" aria-label="EL-GAN schematic">
          <img src="images/teasers/elgan.png" alt="EL-GAN teaser"h2 class="title">
        </figure>
        <div class="content">
          <h2 class="title">
            <a href="https://openaccess.thecvf.com/content_ECCVW_2018/papers/11129/Ghafoorian_EL-GAN_Embedding_Loss_Driven_Generative_Adversarial_Networks_for_Lane_Detection_ECCVW_2018_paper.pdf" target="_blank" rel="noopener">
              EL‑GAN: Embedding Loss Driven Generative Adversarial Networks for Lane Detection
            </a>
          </h2>
          <div class="authors"><strong>M. Ghafoorian</strong>, C. Nugteren, N. Baka, O. Booij, M. Hofmann</div>
          <div class="pills">
            <span class="pill">ECCV 2018 CVRSUAD</span>
          </div>
          <div class="links">
            <a class="badge" href="https://openaccess.thecvf.com/content_ECCVW_2018/papers/11129/Ghafoorian_EL-GAN_Embedding_Loss_Driven_Generative_Adversarial_Networks_for_Lane_Detection_ECCVW_2018_paper.pdf" target="_blank" rel="noopener">Paper (CVF)</a>
			<a class="badge poster" href="https://mohsenghafoorian.github.io/files/elgan_poster.pdf" target="_blank" rel="noopener">Poster</a>
            <button class="copybtn" onclick="copyBib('bib-elgan')">Copy BibTeX</button>
          </div>
          <pre class="bibtex" id="bib-elgan">@inproceedings{Ghafoorian2018ELGAN,
  author    = {Mohsen Ghafoorian and Cedric Nugteren and Nora Baka and Olaf Booij and Michael Hofmann},
  title     = {EL-GAN: Embedding Loss Driven Generative Adversarial Networks for Lane Detection},
  booktitle = {European Conference on Computer Vision Workshops (ECCVW)},
  series    = {Lecture Notes in Computer Science},
  volume    = {11129},
  pages     = {256--272},
  year      = {2018},
  publisher = {Springer},
  doi       = {10.1007/978-3-030-11009-3_15},
  url       = {https://openaccess.thecvf.com/content_ECCVW_2018/papers/11129/Ghafoorian_EL-GAN_Embedding_Loss_Driven_Generative_Adversarial_Networks_for_Lane_Detection_ECCVW_2018_paper.pdf}
}</pre>
        </div>
      </article>

    </section>
  </main>
</div>
</div>
  <!-- ====== Footer with social links from your homepage ====== -->
<div id="footer" class="footer-icons">
  |
  <a href="index.html" target="_blank">Mohsen Ghafoorian

    <span class="ico ico-home" aria-hidden="true">
      <!-- Home icon -->
      <svg viewBox="0 0 24 24" width="16" height="16" role="img" focusable="false">
        <path d="M3 10.5L12 3l9 7.5v9a1 1 0 0 1-1 1h-5v-6H9v6H4a1 1 0 0 1-1-1v-9z" fill="currentColor"/>
      </svg>
    </span>
  </a>  |
  
	<a href="http://www.linkedin.com/pub/mohsen-ghafoorian/53/437/ba3" target="_blank">LinkedIn
    <span class="ico ico-linkedin" aria-hidden="true">
      <!-- LinkedIn -->
      <svg viewBox="0 0 24 24" width="16" height="16" role="img" focusable="false">
        <path fill="currentColor" d="M4.98 3.5A2.5 2.5 0 1 1 5 8.5a2.5 2.5 0 0 1-.02-5zm.52 6h-4v11h4V9.5zm5.5 0h-3.8v11h3.8v-6.1c0-3.25 4.2-3.51 4.2 0V20.5h3.8v-6.89c0-6.1-6.58-5.87-8-2.86V9.5z"/>
      </svg>
    </span>
  </a> |
  <a href="https://twitter.com/mohsen_gh87" target="_blank">Twitter
    <span class="ico ico-x" aria-hidden="true">
      <!-- Twitter/X -->
      <svg viewBox="0 0 24 24" width="16" height="16" role="img" focusable="false">
        <path fill="currentColor" d="M17.5 3.5h3.1l-7.1 8.2 8.2 8.8H18.3L11.8 14l-6.2 6.5H2.5l7.6-8.5L2.5 3.5h4.1l5.6 6 5.3-6z"/>
      </svg>
    </span>
  </a> |
  
  <a href="https://scholar.google.nl/citations?user=989WL-wAAAAJ&hl=en" target="_blank" rel="noopenerhidden="true"> Google Scholar
      <!-- Google Scholar -->
      <svg viewBox="0 0 24 24" width="16" height="16" role="img" focusable="false">
        <path fill="currentColor" d="M12 3l9 6-9 6-9-6 9-6zm0 14.5c3.5 0 6.5 1.2 9 3.5l-18 .0c2.5-2.3 5.5-3.5 9-3.5z"/>
      </svg>
    </span>
    
  </a> |
  
  <a href="https://www.researchgate.net/profile/Mohsen_Ghafoorian5" target="_blank">Researchgate
      <svg viewBox="0 0 24 24" width="16" height="16" role="img" focusable="false">
        <path fill="currentColor" d="M4 4h8.5c3.5 0 6.5 2.7 6.5 6.2 0 3.1-2.3 5.6-5.3 6l3.3 3.8h-3.7L10.8 16H8v3.9H4V4zm9.2 8.1c1.6 0 2.9-1.3 2.9-2.9s-1.3-2.9-2.9-2.9H8v5.8h5.2z"/>
      </svg>
    </span>
  </a> |
  
  <a href="https://www.goodreads.com/user/show/1713-mohsen" target="_blank">Goodreads
  <span class="ico ico-goodreads" aria-hidden="true">
      <!-- Goodreads (G monogram) -->
      <svg viewBox="0 0 24 24" width="16" height="16" role="img" focusable="false">
        <path fill="currentColor" d="M12 3c5 0 8 3.2 8 7.8 0 4.7-3.1 8.2-8.1 8.2-4.9 0-7.9-3.3-7.9-8.2C4 6.2 7 3 12 3zm0 4c-2.3 0-3.9 1.7-3.9 3.8 0 2.2 1.6 3.9 3.9 3.9 2.3 0 3.9-1.7 3.9-3.9 0-2.1-1.6-3.8-3.9-3.8z"/>
      </svg>
    </span>
  </a> |
  
  <a href="https://soundcloud.com/mohsenghafoorian" target="_blank">Sound Cloud
      <!-- SoundCloud -->
      <svg viewBox="0 0 24 24" width="16" height="16" role="img" focusable="false">
        <path fill="currentColor" d="M12.5 8c1.8 0 3.3 1.2 3.6 2.9h2.6c1.7 0 3.1 1.3 3.1 3s-1.4 3-3.1 3h-9.9c-2.1 0-3.7-1.6-3.7-3.6s1.6-3.6 3.7-3.6c.3-2.2 2-3.7 3.7-3.7z"/>
      </svg>
    </span>
  </a> |
</div>
</div>
  <script>
    document.getElementById('y').textContent = new Date().getFullYear();
    function copyBib(id){
      const node = document.getElementById(id);
      const text = node.textContent.trim();
      navigator.clipboard.writeText(text).then(()=>{
        const btns = document.querySelectorAll('button.copybtn');
        const btn = Array.from(btns).find(b=>b.getAttribute('onclick')?.includes(id));
        if(btn){ btn.textContent = 'Copied!'; setTimeout(()=>btn.textContent='Copy BibTeX', 1500); }
      }).catch(()=>{ alert('Copy failed. Please select and copy manually.'); });
    }
  </script>
</body>

</html>
